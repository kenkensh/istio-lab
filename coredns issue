
[root@lab1 ~]# kubectl get pod -n kube-system -o wide
NAME                           READY   STATUS             RESTARTS   AGE    IP             NODE   NOMINATED NODE
coredns-6c66ffc55b-5nx6z       0/1     CrashLoopBackOff   3          85s    10.244.0.7     lab1   <none>
coredns-6c66ffc55b-wc8vc       0/1     CrashLoopBackOff   3          95s    10.244.0.6     lab1   <none>
etcd-lab1                      1/1     Running            2          91m    11.11.11.111   lab1   <none>
kube-apiserver-lab1            1/1     Running            2          91m    11.11.11.111   lab1   <none>
kube-controller-manager-lab1   1/1     Running            2          91m    11.11.11.111   lab1   <none>
kube-flannel-ds-hs6ht          1/1     Running            0          8m4s   11.11.11.111   lab1   <none>
kube-flannel-ds-kjnp7          1/1     Running            1          8m4s   11.11.11.113   lab3   <none>
kube-flannel-ds-xtd8m          1/1     Running            1          8m4s   11.11.11.112   lab2   <none>
kube-proxy-28cmz               1/1     Running            2          73m    11.11.11.112   lab2   <none>
kube-proxy-b9z28               1/1     Running            2          92m    11.11.11.111   lab1   <none>
kube-proxy-l99m2               1/1     Running            2          73m    11.11.11.113   lab3   <none>
kube-scheduler-lab1            1/1     Running            2          91m    11.11.11.111   lab1   <none>
[root@lab1 ~]# kubectl describe pod coredns-6c66ffc55b-5nx6z -n kube-system
Name:               coredns-6c66ffc55b-5nx6z
Namespace:          kube-system
Priority:           0
PriorityClassName:  <none>
Node:               lab1/11.11.11.111
Start Time:         Wed, 28 Jul 2021 14:54:38 +0000
Labels:             k8s-app=kube-dns
                    pod-template-hash=6c66ffc55b
Annotations:        <none>
Status:             Running
IP:                 10.244.0.7
Controlled By:      ReplicaSet/coredns-6c66ffc55b
Containers:
  coredns:
    Container ID:  docker://742af218047d6e684ba4f7cae7a26f225ea0c7c17858593cb5ded1bf071c3c57
    Image:         registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:1.2.2
    Image ID:      docker-pullable://registry.cn-hangzhou.aliyuncs.com/google_containers/coredns@sha256:3e2be1cec87aca0b74b7668bbe8c02964a95a402e45ceb51b2252629d608d03a
    Ports:         53/UDP, 53/TCP, 9153/TCP
    Host Ports:    0/UDP, 0/TCP, 0/TCP
    Args:
      -conf
      /etc/coredns/Corefile
    State:          Waiting
      Reason:       CrashLoopBackOff
    Last State:     Terminated
      Reason:       Error
      Exit Code:    1
      Started:      Wed, 28 Jul 2021 14:55:46 +0000
      Finished:     Wed, 28 Jul 2021 14:55:53 +0000
    Ready:          False
    Restart Count:  3
    Limits:
      memory:  170Mi
    Requests:
      cpu:        100m
      memory:     70Mi
    Liveness:     http-get http://:8080/health delay=60s timeout=5s period=10s #success=1 #failure=5
    Environment:  <none>
    Mounts:
      /etc/coredns from config-volume (ro)
      /var/run/secrets/kubernetes.io/serviceaccount from coredns-token-jqsj2 (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             False 
  ContainersReady   False 
  PodScheduled      True 
Volumes:
  config-volume:
    Type:      ConfigMap (a volume populated by a ConfigMap)
    Name:      coredns
    Optional:  false
  coredns-token-jqsj2:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  coredns-token-jqsj2
    Optional:    false
QoS Class:       Burstable
Node-Selectors:  <none>
Tolerations:     CriticalAddonsOnly
                 node-role.kubernetes.io/master:NoSchedule
                 node.kubernetes.io/not-ready:NoExecute for 300s
                 node.kubernetes.io/unreachable:NoExecute for 300s
Events:
  Type     Reason     Age                 From               Message
  ----     ------     ----                ----               -------
  Normal   Scheduled  105s                default-scheduler  Successfully assigned kube-system/coredns-6c66ffc55b-5nx6z to lab1
  Normal   Pulled     37s (x4 over 104s)  kubelet, lab1      Container image "registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:1.2.2" already present on machine
  Normal   Created    37s (x4 over 104s)  kubelet, lab1      Created container
  Normal   Started    37s (x4 over 104s)  kubelet, lab1      Started container
  Warning  BackOff    1s (x9 over 89s)    kubelet, lab1      Back-off restarting failed container

这里可以根据自己的原因来解决，其实原因不过两个，可能是你的容器lo回环找不到你的容器，有可能就是你的本地/etc/resolv.conf下的dns
[root@k8s-master coredns]# vim /etc/resolv.conf

这里我指定是nameserver 8.8.8.8


[root@lab1 ~]# vi /etc/resolv.conf 

# Generated by NetworkManager
search lan
#nameserver 10.0.2.3
nameserver 8.8.8.8
~
~
~
"/etc/resolv.conf" 4L, 81C written

[root@lab1 ~]# kubectl get pod -n kube-system
NAME                           READY   STATUS             RESTARTS   AGE
coredns-6c66ffc55b-5nx6z       0/1     CrashLoopBackOff   6          7m34s
coredns-6c66ffc55b-wc8vc       0/1     CrashLoopBackOff   6          7m44s
etcd-lab1                      1/1     Running            2          98m
kube-apiserver-lab1            1/1     Running            2          98m
kube-controller-manager-lab1   1/1     Running            2          98m
kube-flannel-ds-hs6ht          1/1     Running            0          14m
kube-flannel-ds-kjnp7          1/1     Running            1          14m
kube-flannel-ds-xtd8m          1/1     Running            1          14m
kube-proxy-28cmz               1/1     Running            2          79m
kube-proxy-b9z28               1/1     Running            2          98m
kube-proxy-l99m2               1/1     Running            2          79m
kube-scheduler-lab1            1/1     Running            2          98m

要过上几分钟，就正常了

[root@lab1 ~]# kubectl get pod -n kube-system
NAME                           READY   STATUS    RESTARTS   AGE
coredns-6c66ffc55b-5nx6z       1/1     Running   7          15m
coredns-6c66ffc55b-wc8vc       1/1     Running   7          15m
etcd-lab1                      1/1     Running   4          106m
kube-apiserver-lab1            1/1     Running   4          106m
kube-controller-manager-lab1   1/1     Running   4          106m
kube-flannel-ds-hs6ht          1/1     Running   1          22m
kube-flannel-ds-kjnp7          1/1     Running   1          22m
kube-flannel-ds-xtd8m          1/1     Running   1          22m
kube-proxy-28cmz               1/1     Running   2          88m
kube-proxy-b9z28               1/1     Running   4          106m
kube-proxy-l99m2               1/1     Running   2          87m
kube-scheduler-lab1            1/1     Running   4          106m
[root@lab1 ~]# 
